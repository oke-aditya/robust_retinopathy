{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Tue Apr  6 09:23:42 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.8.1+cu111 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.9.1+cu111 which is incompatible.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q quickvision==0.2.0","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torchtext -y\n!pip uninstall torchaudio -y","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\nFound existing installation: torchaudio 0.8.1\nUninstalling torchaudio-0.8.1:\n  Successfully uninstalled torchaudio-0.8.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms as T\nfrom tqdm import tqdm\nfrom quickvision.models.classification import cnn\nfrom quickvision import utils\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"1.8.1+cu111\n","output_type":"stream"}]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_DIR = \"../input/aptos2019-blindness-detection/\"\nTRAIN_DIR = \"../input/aptos2019-blindness-detection/train_images\"\nCSV_PATH = \"../input/aptos2019-blindness-detection/train.csv\"\nMODEL_PATH = \"./\"\n\n\nLEARNING_RATE = 1e-3\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 32\nNUM_WORKERS = 2\nEPOCHS = 2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class RetinopathyDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.image_dir = image_dir\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # img_name = os.path.join('../input/aptos2019-blindness-detection/train_images',\n        #                         self.data.loc[idx, 'id_code'] + '.png')\n\n        img_name = os.path.join(self.image_dir, self.data.loc[idx, 'id_code'] + '.png')\n\n        image = Image.open(img_name)\n        image = image.resize((512, 512), resample=Image.BILINEAR)\n        label = torch.tensor(self.data.loc[idx, 'diagnosis'], dtype=torch.long)\n\n        if self.transform is not None:\n            img = self.transform(image)\n\n        return (img, label)","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"utils.seed_everything(42)\nutils.set_debug_apis(False)\n\ntrain_trasforms = T.Compose([\n    T.ToTensor(),\n#     T.Resize((224, 224)),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    # T.ConvertImageDtype(torch.float32),\n    # T.CenterCrop((224, 224)),\n])\n\ntrain_dataset = RetinopathyDataset(TRAIN_DIR, CSV_PATH, transform=train_trasforms)\n# model = model.create_model(\"\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE,\n                      shuffle=False, num_workers=NUM_WORKERS)\n\n\nfor batch_idx, (inputs, target) in enumerate(train_loader):\n    print(batch_idx)\n#     print(inputs)\n    print(target)\n    break","metadata":{"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"0\ntensor([2, 4, 1, 0, 0, 4, 0, 2, 2, 1, 0, 2, 0, 3, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2,\n        0, 2, 0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"model = cnn.create_cnn(\"resnet50\", num_classes=5, pretrained=None)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\n# # if config.USE_AMP:\n# #     from torch.cuda import amp\n# #     scaler = amp.GradScaler()\n\n\n# print(device)\nmodel = model.to(\"cuda\")\n\nfor epoch in tqdm(range(EPOCHS)):\n    metrics = cnn.train_step(model, train_loader, criterion, device, optimizer)\n\n# Save model every epoch\ntorch.save(model.state_dict(), MODEL_PATH + f\"_{epoch}\" + \".pt\")","metadata":{"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"  0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Batch Train Time: 11.064 (11.064)  Loss:  1.8092 (1.8092)  Top 1 Accuracy: 18.7500 (18.7500)  Top 5 Accuracy: 100.0000 (100.0000)\nBatch Train Time: 0.864 (4.005)  Loss:  1.2235 (1.2615)  Top 1 Accuracy: 46.8750 (49.5668)  Top 5 Accuracy: 100.0000 (100.0000)\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 1/2 [07:38<07:38, 458.43s/it]","output_type":"stream"},{"name":"stdout","text":"Batch Train Time: 3.198 (3.985)  Loss:  1.0995 (1.2526)  Top 1 Accuracy: 50.0000 (50.3550)  Top 5 Accuracy: 100.0000 (100.0000)\nTime taken for train step = 458.4207293987274 sec\nBatch Train Time: 8.064 (8.064)  Loss:  1.1764 (1.1764)  Top 1 Accuracy: 50.0000 (50.0000)  Top 5 Accuracy: 100.0000 (100.0000)\nBatch Train Time: 0.874 (4.010)  Loss:  1.1227 (1.1753)  Top 1 Accuracy: 59.3750 (57.6423)  Top 5 Accuracy: 100.0000 (100.0000)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [15:14<00:00, 457.20s/it]","output_type":"stream"},{"name":"stdout","text":"Batch Train Time: 0.394 (3.964)  Loss:  0.9721 (1.1603)  Top 1 Accuracy: 57.1429 (58.2196)  Top 5 Accuracy: 100.0000 (100.0000)\nTime taken for train step = 455.9706521034241 sec\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}