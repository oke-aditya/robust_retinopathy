{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Tue May 11 19:44:38 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install -q torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n!pip install timm","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n\u001b[K     |████████████████████████████████| 287 kB 4.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\nInstalling collected packages: timm\nSuccessfully installed timm-0.4.5\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall torchtext -y\n!pip uninstall torchaudio -y","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found existing installation: torchtext 0.8.0a0+cd6902d\nUninstalling torchtext-0.8.0a0+cd6902d:\n  Successfully uninstalled torchtext-0.8.0a0+cd6902d\nFound existing installation: torchaudio 0.7.0a0+ac17b64\nUninstalling torchaudio-0.7.0a0+ac17b64:\n  Successfully uninstalled torchaudio-0.7.0a0+ac17b64\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport timm\nimport random\nimport time\nfrom collections import OrderedDict\nfrom torch.cuda import amp\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms as T\nfrom torchvision.io import read_image\nfrom tqdm import tqdm\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_DIR = \"../input/aptos2019-blindness-detection/\"\nTRAIN_DIR = \"../input/aptos2019-blindness-detection/train_images\"\nCSV_PATH = \"../input/aptos2019-blindness-detection/train.csv\"\nMODEL_PATH = \".\"\n\n\nTRAIN_SPLIT = 0.8\n# Automaticllay\n# VAL_SPLIT = 0.2\n\nLEARNING_RATE = 1e-3\nTRAIN_BATCH_SIZE = 4\nVALID_BATCH_SIZE = 4\n\nNUM_WORKERS = 2\nEPOCHS = 2\n\nIMG_WIDTH = 768\nIMG_HEIGHT = 768\n\nMODEL_NAME = \"mobilenetv3_large_100\"\n\nMODEL_SAVE = MODEL_PATH + MODEL_NAME\nUSE_AMP = True\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n@torch.no_grad()\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n    return [correct[:k].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]\n\n\ndef set_debug_apis(state: bool = False):\n    torch.autograd.profiler.profile(enabled=state)\n    torch.autograd.profiler.emit_nvtx(enabled=state)\n    torch.autograd.set_detect_anomaly(mode=state)\n\n\ndef seed_everything(seed):\n    \"\"\"\n    Makes code deterministic using a given seed.\n    Internally sets all seeds of torch, numpy and random.\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n\ndef print_size_of_model(model):\n    torch.save(model.state_dict(), \"temp.p\")\n    print(\"Size (MB):\", os.path.getsize(\"temp.p\") / 1e6)\n    os.remove(\"temp.p\")\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class RetinopathyDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transforms=None):\n        self.data = pd.read_csv(csv_file)\n        self.transforms = transforms\n        self.image_dir = image_dir\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # img_name = os.path.join('../input/aptos2019-blindness-detection/train_images',\n        #                         self.data.loc[idx, 'id_code'] + '.png')\n\n        img_name = os.path.join(self.image_dir, self.data.loc[idx, 'id_code'] + '.png')\n\n        tensor_image = read_image(img_name)\n        label = torch.tensor(self.data.loc[idx, 'diagnosis'], dtype=torch.long)\n\n        if self.transforms is not None:\n            tensor_image = self.transforms(tensor_image)\n\n        return (tensor_image, label)","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_step(model: nn.Module, train_loader, criterion,\n               device: str, optimizer,\n               scheduler=None, num_batches: int = None,\n               log_interval: int = 100,\n               scaler=None,):\n    \"\"\"\n    Performs one step of training. Calculates loss, forward pass, computes gradient and returns metrics.\n    Args:\n        model : A pytorch CNN Model.\n        train_loader : Train loader.\n        criterion : Loss function to be optimized.\n        device : \"cuda\" or \"cpu\"\n        optimizer : Torch optimizer to train.\n        scheduler : Learning rate scheduler.\n        num_batches : (optional) Integer To limit training to certain number of batches.\n        log_interval : (optional) Defualt 100. Integer to Log after specified batch ids in every batch.\n        scaler: (optional)  Pass torch.cuda.amp.GradScaler() for fp16 precision Training.\n    \"\"\"\n\n    model = model.to(device)\n    start_train_step = time.time()\n    metrics = OrderedDict()\n    model.train()\n    last_idx = len(train_loader) - 1\n    batch_time_m = AverageMeter()\n    # data_time_m = AverageMeter()\n    losses_m = AverageMeter()\n    top1_m = AverageMeter()\n    top5_m = AverageMeter()\n    cnt = 0\n    batch_start = time.time()\n    # num_updates = epoch * len(loader)\n\n    for batch_idx, (inputs, target) in enumerate(train_loader):\n        last_batch = batch_idx == last_idx\n        # data_time_m.update(time.time() - batch_start)\n        inputs = inputs.to(device)\n        target = target.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        if scaler is not None:\n            with amp.autocast():\n                output = model(inputs)\n                loss = criterion(output, target)\n                # Scale the loss using Grad Scaler\n            scaler.scale(loss).backward()\n            # Step using scaler.step()\n            scaler.step(optimizer)\n            # Update for next iteration\n            scaler.update()\n\n        else:\n            output = model(inputs)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n        if scheduler is not None:\n            scheduler.step()\n\n        cnt += 1\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n\n        top1_m.update(acc1.item(), output.size(0))\n        top5_m.update(acc5.item(), output.size(0))\n        losses_m.update(loss.item(), inputs.size(0))\n\n        batch_time_m.update(time.time() - batch_start)\n        batch_start = time.time()\n        if last_batch or batch_idx % log_interval == 0:  # If we reach the log intervel\n            print(\n                \"Batch Train Time: {batch_time.val:.3f} ({batch_time.avg:.3f})  \"\n                \"Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  \"\n                \"Top 1 Accuracy: {top1.val:>7.4f} ({top1.avg:>7.4f})  \"\n                \"Top 5 Accuracy: {top5.val:>7.4f} ({top5.avg:>7.4f})\".format(\n                    batch_time=batch_time_m, loss=losses_m, top1=top1_m, top5=top5_m))\n\n        if num_batches is not None:\n            if cnt >= num_batches:\n                end_train_step = time.time()\n                metrics[\"loss\"] = losses_m.avg\n                metrics[\"top1\"] = top1_m.avg\n                metrics[\"top5\"] = top5_m.avg\n                print(f\"Done till {num_batches} train batches\")\n                print(f\"Time taken for train step = {end_train_step - start_train_step} sec\")\n                return metrics\n\n    metrics[\"loss\"] = losses_m.avg\n    metrics[\"top1\"] = top1_m.avg\n    metrics[\"top5\"] = top5_m.avg\n    end_train_step = time.time()\n    print(f\"Time taken for train step = {end_train_step - start_train_step} sec\")\n    return metrics","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef val_step(model: nn.Module, val_loader, criterion,\n             device: str, num_batches=None,\n             log_interval: int = 100):\n\n    \"\"\"\n    Performs one step of validation. Calculates loss, forward pass and returns metrics.\n    Args:\n        model : A pytorch CNN Model.\n        val_loader : Validation loader.\n        criterion : Loss function to be optimized.\n        device : \"cuda\" or \"cpu\"\n        num_batches : (optional) Integer To limit validation to certain number of batches.\n        log_interval : (optional) Defualt 100. Integer to Log after specified batch ids in every batch.\n    \"\"\"\n\n    model = model.to(device)\n    start_val_step = time.time()\n    last_idx = len(val_loader) - 1\n    batch_time_m = AverageMeter()\n    # data_time_m = AverageMeter()\n    losses_m = AverageMeter()\n    top1_m = AverageMeter()\n    top5_m = AverageMeter()\n    cnt = 0\n    model.eval()\n    batch_start = time.time()\n    metrics = OrderedDict()\n\n    for batch_idx, (inputs, target) in enumerate(val_loader):\n        last_batch = batch_idx == last_idx\n        inputs = inputs.to(device)\n        target = target.to(device)\n\n        output = model(inputs)\n        loss = criterion(output, target)\n        cnt += 1\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n        reduced_loss = loss.data\n\n        losses_m.update(reduced_loss.item(), inputs.size(0))\n        top1_m.update(acc1.item(), output.size(0))\n        top5_m.update(acc5.item(), output.size(0))\n        batch_time_m.update(time.time() - batch_start)\n\n        batch_start = time.time()\n\n        if (last_batch or batch_idx % log_interval == 0):  # If we reach the log intervel\n            print(\n                \"Batch Inference Time: {batch_time.val:.3f} ({batch_time.avg:.3f})  \"\n                \"Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  \"\n                \"Top 1 Accuracy: {top1.val:>7.4f} ({top1.avg:>7.4f})  \"\n                \"Top 5 Accuracy: {top5.val:>7.4f} ({top5.avg:>7.4f})\".format(\n                    batch_time=batch_time_m, loss=losses_m, top1=top1_m, top5=top5_m))\n\n        if num_batches is not None:\n            if cnt >= num_batches:\n                end_val_step = time.time()\n                metrics[\"loss\"] = losses_m.avg\n                metrics[\"top1\"] = top1_m.avg\n                metrics[\"top5\"] = top5_m.avg\n                print(f\"Done till {num_batches} validation batches\")\n                print(f\"Time taken for validation step = {end_val_step - start_val_step} sec\")\n                return metrics\n\n    metrics[\"loss\"] = losses_m.avg\n    metrics[\"top1\"] = top1_m.avg\n    metrics[\"top5\"] = top5_m.avg\n    print(\"Finished the validation epoch\")\n\n    end_val_step = time.time()\n    print(f\"Time taken for validation step = {end_val_step - start_val_step} sec\")\n    return metrics\n","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"seed_everything(42)\nset_debug_apis(False)\n\ntrain_trasforms = T.Compose([\n    T.ConvertImageDtype(torch.float32),\n    T.Resize((IMG_WIDTH, IMG_HEIGHT)),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nfull_dataset = RetinopathyDataset(TRAIN_DIR, CSV_PATH, transforms=train_trasforms)\n\ntrain_size = int(TRAIN_SPLIT * len(full_dataset))\ntest_size = len(full_dataset) - train_size\n\ntrain_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(full_dataset, batch_size=TRAIN_BATCH_SIZE,\n                          shuffle=False, num_workers=NUM_WORKERS, drop_last=True, pin_memory=False)\n\nval_loader = DataLoader(val_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False,\n                        num_workers=NUM_WORKERS, drop_last=True, pin_memory=False)\n\n# for batch_idx, (inputs, target) in enumerate(train_loader):\n#     print(batch_idx)\n#     # print(inputs)\n#     print(target)\n#     break","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=5)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\nif USE_AMP:\n    from torch.cuda import amp\n    scaler = amp.GradScaler()","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_loss = []\ntrain_top1_acc = []\nval_loss = []\nval_top1_acc = []\n\nfor epoch in tqdm(range(EPOCHS)):\n    train_metrics = train_step(model, train_loader, criterion, device, optimizer, scaler=scaler)\n    train_loss.append(train_metrics[\"loss\"])\n    train_top1_acc.append(train_metrics[\"top1\"])\n\n    val_metrics = val_step(model, val_loader, criterion, device)\n    val_loss.append(val_metrics[\"loss\"])\n    val_top1_acc.append(val_metrics[\"top1\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Batch Train Time: 4.680 (4.680)  Loss:  3.5647 (3.5647)  Top 1 Accuracy:  0.0000 ( 0.0000)  Top 5 Accuracy: 100.0000 (100.0000)\nBatch Train Time: 0.559 (0.606)  Loss:  3.0890 (3.0636)  Top 1 Accuracy: 50.0000 (53.7129)  Top 5 Accuracy: 100.0000 (100.0000)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}